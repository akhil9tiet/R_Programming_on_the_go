c = seq(from =1, to =20, by=3)
c
c = seq(from =1, to =100, by=3+c)
c = seq(from =1, to =100, by=(3+c))
i= c
c = seq(from =1, to =100, by=3+i
)
c = seq(from =1, to =100, by=(3+i))
clr
cl()
x= 1:5
x[3]
s = 1
a=2
c=a+s
print c
print(c)
print("Hello World from Akhil")
getwd
getwd()
getwd()
R.version()
R.version
ucsc<-dbConnect(MySQL(),user="genome", host= "genome-mysql.cse.ucsc.edu")
htmlcode
con= url("https://scholar.google.co.in/citations?user=HI-I6C0AAAAJ&hl=en&oi=ao")
htmlcode= readLines(con)
close(con)
htmlcode
xpathSapply(html, "//title", xmlValue)
html
xpathSApply(html, "//title", xmlValue)
xpathSApply(parsedHTML, "//title", xmlValue)
library(httr);
html2= GET("https://scholar.google.co.in/citations?user=HI-I6C0AAAAJ&hl=en&oi=ao")
content2= content(html2, as="text")
parsedHTML = htmlParse(content2, astext= TRUE)
xpathSApply(parsedHTML, "//title", xmlValue)
library(httr);
html2= GET("https://scholar.google.co.in/citations?user=HI-I6C0AAAAJ&hl=en&oi=ao")
content2= content(html2, as="text")
parsedHTML = htmlParse(content2, astext= TRUE)
xpathSApply(parsedHTML, "//title", xmlValue)
sqldf("select pwgtp1 from acs where AGEP < 50")
#Question 5
#Read this data set into R and report the sum of the numbers in the fourth column.
#https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for
#Original source of the data: http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for
set.seed
set.seed(13435)
x<-data.frame("var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15))
x
x<-x[sample(1:5),]; x$var2[c(1,3)]=NA
x
head(mydata)
mydata = read.csv("C:/Users/akhgupta/Desktop/Data_Science_Coursera/R_programming/2.Coursera_Data Science Specialization_ Data Cleaning/week3/q1/American_community_micro_dataset.csv")
mydata
library(dplyr)
mydata = read.csv("C:/Users/akhgupta/Desktop/Data_Science_Coursera/R_programming/2.Coursera_Data Science Specialization_ Data Cleaning/week3/q1/American_community_micro_dataset.csv")
summary(mydata)
head(filter_data,3)
header(filter_data,3)
filter_data= filter(mydata,ACR==3&AGR==6)
filter_data
filter_data= filter(mydata,ACR=3&AGR=6)
filter_data= filter(mydata,ACR==3&AG==6)
filter_data= filter(mydata,ACR>2&AG>5)
filter_data= filter(mydata,ACR>2&AGS>5)
filter_data= filter(mydata, ACR>2&AGS>5)
filter_data= filter(mydata, ACR>2 , AGS>5)
filter_data= filter(mydata, ACR=3 , AGS=6)
filter_data= filter(mydata, ACR==3 , AGS==6)
filter_data= filter(mydata, ACR==3 & AGS==6)
filter_data= filter(mydata, ACR=3 & AGS=6)
head(which(agricultureLogical), 3)
dst1 = "C:/Users/akhgupta/Desktop/Data_Science_Coursera/R_programming/2.Coursera_Data Science Specialization_ Data Cleaning/week3/q1/American_community_micro_dataset.csv"
download.file(fileurl1, dst1, method = 'curl')
##download.file(fileurl1, dst1, method = 'curl')
data1 = read.csv(dst1)
agricultureLogical = data1$ACR == 3 & data1$AGS == 6
head(which(agricultureLogical), 3)
fileurl2 = 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
dst2 = "C:/Users/akhgupta/Desktop/Data_Science_Coursera/R_programming/2.Coursera_Data Science Specialization_ Data Cleaning/week3/q2/getdata_jeff.jpg"
download.file(fileurl2, dst2, mode = 'wb', method = 'curl')
data2 = readJPEG(dst2, native = TRUE)
quantile(data2, probs = c(0.3, 0.8))
data2 = readJPEG(dst2, native = TRUE)
dst2 = "C:/Users/akhgupta/Desktop/Data_Science_Coursera/R_programming/2.Coursera_Data Science Specialization_ Data Cleaning/week3/q2/getdata_jeff.jpg"
#download.file(fileurl2, dst2, mode = 'wb', method = 'curl')
data2 = readJPEG(dst2, native = TRUE)
data2 = read.JPEG(dst2, native = TRUE)
quantile(picture, probs = c(0.3, 0.8) )
# write the file url and file destination to an object
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
file.dest <- 'jeff.jpg'
# download from the URL
download.file(file.url, file.dest, mode='wb' )
# load package
library(jpeg)
# load the data
picture <- readJPEG('jeff.jpg', native=TRUE)
# get the quantile info
quantile(picture, probs = c(0.3, 0.8) )
# write the file url and file destination to an object
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
file.dest <- 'jeff.jpg'
# download from the URL
download.file(file.url, file.dest, mode='wb' )
# load package
library(jpeg)
# load the data
picture <- readJPEG('jeff.jpg', native=TRUE)
# get the quantile info
quantile(picture, probs = c(0.3, 0.8) )
fileurl1 = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
dst1 = "C:/Users/akhgupta/Desktop/Data_Science_Coursera/R_programming/2.Coursera_Data Science Specialization_ Data Cleaning/week3/"
download.file(fileurl1, dst1, method = 'curl')
data1 = read.csv(dst1)
fileurl2 = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
dst1 = "C:/Users/akhgupta/Desktop/Data_Science_Coursera/R_programming/2.Coursera_Data Science Specialization_ Data Cleaning/week3/"
download.file(fileurl2, dst1, method = 'curl')
data1 = read.csv(dst1)
'''
Load the Gross Domestic Product data for the 190 ranked countries in this data set:
https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv
Load the educational data from this data set:
https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv
Match the data based on the country shortcode. How many of the IDs match? Sort the data frame in descending order by GDP rank (so United States is last). What is the 13th country in the resulting data frame?
Original data sources:
http://data.worldbank.org/data-catalog/GDP-ranking-table
http://data.worldbank.org/data-catalog/ed-stats
'''
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP.csv'
download.file(file.url, file.dest )
# specify the right lines
rowNames <- seq(10,200, 2)
# read the data
gdp <- read.csv('GDP.csv', header=F, skip=5, nrows=190)
View(gdp)
# second data file
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
file.dest <- 'GDP2.csv'
download.file(file.url, file.dest )
# read second file
fed <- read.csv('GDP2.csv')
View(fed)
# merge datasets
combined <- merge(gdp, fed, by.x='V1', by.y='CountryCode', sort=TRUE)
View(combined)
# Q3.
# sort the data
combined[with(combined, order(-V2) )]
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP.csv'
download.file(file.url, file.dest )
# specify the right lines
rowNames <- seq(10,200, 2)
# read the data
gdp <- read.csv('GDP.csv', header=F, skip=5, nrows=190)
View(gdp)
# second data file
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
file.dest <- 'GDP2.csv'
download.file(file.url, file.dest )
# read second file
fed <- read.csv('GDP2.csv')
View(fed)
# merge datasets
combined <- merge(gdp, fed, by.x='V1', by.y='CountryCode', sort=TRUE)
View(combined)
# Q3.
# sort the data
combined[with(combined, order(-V2) )]
# Q4.
# OECD
mean(combined[combined$Income.Group=='High income: OECD',]$V2)
# non OECD
mean(combined[combined$Income.Group=='High income: nonOECD',]$V2)
quentile <- c(0.2,0.4,0.6,0.8,1)
q <- quantile(combined$V2, quentile)
q1 <- combined$V2 <= 38
xtabs(q1 ~ combined$Income.Group)
fileurl1 = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
dst1 = "q1dataset.csv"
download.file(fileurl1, dst1, method = 'curl')
data1 = read.csv(dst1)
strspit(names(data1),"wgtp")
fileurl1 = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
dst1 = "C:/Users/akhgupta/Desktop/Data_Science_Coursera/R_programming/2.Coursera_Data Science Specialization_ Data Cleaning/week4/q1dataset.csv"
download.file(fileurl1, dst1, method = 'curl')
data1 = read.csv(dst1)
strsplit(names(data1),"wgtp")
121
fileurl1 = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
dst1 = "C:/Users/akhgupta/Desktop/Data_Science_Coursera/R_programming/2.Coursera_Data Science Specialization_ Data Cleaning/week4/q1dataset.csv"
download.file(fileurl1, dst1, method = 'curl')
data1 = read.csv(dst1)
strsplit(names(data1),"wgtp")[123]
fileurl1 = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
dst1 = "C:/Users/akhgupta/Desktop/Data_Science_Coursera/R_programming/2.Coursera_Data Science Specialization_ Data Cleaning/week4/q2dataset.csv"
download.file(fileurl1, dst1, method = 'curl')
data1 = read.csv(dst1)
avg(gsub(",","",data1))
(gsub(",","",data1)
fileurl1 = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
dst1 = "C:/Users/akhgupta/Desktop/Data_Science_Coursera/R_programming/2.Coursera_Data Science Specialization_ Data Cleaning/week4/q2dataset.csv"
download.file(fileurl1, dst1, method = 'curl')
data1 = read.csv(dst1)
fileurl1 = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
dst2 = "C:/Users/akhgupta/Desktop/Data_Science_Coursera/R_programming/2.Coursera_Data Science Specialization_ Data Cleaning/week4/q2dataset.csv"
download.file(fileurl1, dst2, method = 'curl')
data1 = read.csv(dst2)
dst2 = "q2dataset.csv"
fileurl1 = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
dst2 = "q2dataset.csv"
download.file(fileurl1, dst2, method = 'curl')
data1 = read.csv(dst2)
(gsub(",","",data1)
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP4.csv'
download.file(file.url, file.dest, method='wget')
# read the data
GDP <- read.csv(file.dest, skip=4, nrows=190)
# substitute comma's out
GDPdol <- gsub(",", "", GDP$X.4)
# convert to integer and calculate mean
GDPdol <- as.integer(GDPdol)
mean(GDPdol, na.rm=TRUE)
# attach the GDP data frame
attach(GDP)
grep("^United",GDP$V4)
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP4.csv'
download.file(file.url, file.dest, method='wget')
# read the data
GDP <- read.csv(file.dest, skip=4, nrows=190)
# substitute comma's out
GDPdol <- gsub(",", "", GDP$X.4)
# convert to integer and calculate mean
GDPdol <- as.integer(GDPdol)
mean(GDPdol, na.rm=TRUE)
# attach the GDP data frame
attach(GDP)
grep("^United",GDP$V4)
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP4.csv'
download.file(file.url, file.dest, method='wget')
# read the data
GDP <- read.csv(file.dest, skip=4, nrows=190)
# substitute comma's out
GDPdol <- gsub(",", "", GDP$X.4)
# convert to integer and calculate mean
GDPdol <- as.integer(GDPdol)
mean(GDPdol, na.rm=TRUE)
# attach the GDP data frame
attach(GDP)
grep("^United",GDP$V4)
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP4.csv'
download.file(file.url, file.dest, method='wget')
# read the data
GDP <- read.csv(file.dest, skip=4, nrows=190)
# substitute comma's out
GDPdol <- gsub(",", "", GDP$X.4)
# convert to integer and calculate mean
GDPdol <- as.integer(GDPdol)
mean(GDPdol, na.rm=TRUE)
# attach the GDP data frame
attach(GDP)
grep("^United",GDP$V4)
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP4.csv'
download.file(file.url, file.dest, method='wget')
# read the data
GDP <- read.csv(file.dest, skip=4, nrows=190)
# substitute comma's out
GDPdol <- gsub(",", "", GDP$X.4)
# convert to integer and calculate mean
GDPdol <- as.integer(GDPdol)
mean(GDPdol, na.rm=TRUE)
# attach the GDP data frame
attach(GDP)
grep("^United",GDP$V4)
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP4.csv'
download.file(file.url, file.dest, method='wget')
# read the data
GDP <- read.csv(file.dest, skip=4, nrows=190)
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP4.csv'
download.file(file.url, file.dest, method='curl')
# read the data
GDP <- read.csv(file.dest, skip=4, nrows=190)
setwd('C:/Users/akhgupta/Desktop/Data_Science_Coursera/R_programming/2.Coursera_Data Science Specialization_ Data Cleaning/week4/')
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP4.csv'
download.file(file.url, file.dest, method='curl')
# read the data
GDP <- read.csv(file.dest, skip=4, nrows=190)
setwd('C:/Users/akhgupta/Desktop/Data_Science_Coursera/R_programming/2.Coursera_Data Science Specialization_ Data Cleaning/week4/')
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP4.csv'
download.file(file.url, file.dest, method='wget')
# read the data
GDP <- read.csv(file.dest, skip=4, nrows=190)
GDP <- read.csv(file.dest, skip=4, nrows=190, 'r')
setwd('C:/Users/akhgupta/Desktop/Data_Science_Coursera/R_programming/2.Coursera_Data Science Specialization_ Data Cleaning/week4/')
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP4.csv'
download.file(file.url, file.dest)
# read the data
GDP <- read.csv(file.dest, skip=4, nrows=190, 'r')
GDP <- read.csv(file.dest, skip=4, nrows=190, header=TRUE)
# substitute comma's out
GDPdol <- gsub(",", "", GDP$X.4)
# convert to integer and calculate mean
GDPdol <- as.integer(GDPdol)
mean(GDPdol, na.rm=TRUE)
# attach the GDP data frame
attach(GDP)
grep("^United",GDP$V4)
attach(GDP)
grep("^United",countryNames)
grepl("^United",GDP$V4)
grep("^United",GDP$V4, value= TRUE)
setwd('C:/Users/akhgupta/Desktop/Data_Science_Coursera/R_programming/2.Coursera_Data Science Specialization_ Data Cleaning/week4/')
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
file.dest <- 'GDP4.csv'
download.file(file.url, file.dest)
GDP <- read.csv(file.dest, skip=4, nrows=190, header=TRUE)
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
file.dest <- 'edu.csv'
download.file(file.url, file.dest)
edu <- read.csv(file.dest, header= TRUE)
# merge the datasets
merged <- merge(GDP, edu, by.x = 'X', by.y = 'CountryCode')
# extract the information
fy.june <- grep('Fiscal year end: June', merged$Special.Notes)
length(fy.june)
table(day)
install.packages('quantmod')
library(quantmod)
# load Amazon stock data
amzn = getSymbols("AMZN",auto.assign=FALSE)
# extract the index
sampleTimes = index(amzn)
# create logical for year 2012
year2012 <- grepl('2012-*', sampleTimes)
# count 2012 observations (i.e. true)
table(year2012)
# subset based on 2012
sampleTimes2012 <- subset(sampleTimes, year2012)
# convert to day of week
day <- format(sampleTimes2012, '%A')
# count each day
table(day)
